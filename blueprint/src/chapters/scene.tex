\chapter{Ket-bra operators}

\section{Kets and bras}
\begin{definition}\label{ket}\lean{ket}\leanok
  A \textit{ket} operator $\ket{\cdot}$ on a Hilbert space $\Hcal$ is defined as the linear map $\Bcal(\Hcal,\Bcal(\CC,\Hcal))$ and is given by $x\mapsto(\alpha\mapsto\alpha x)$.
\end{definition}
\begin{definition}\label{bra}\lean{bra}\leanok
  A \textit{bra} operator $\bra{\cdot}$ on a Hilbert space $\Hcal$ is defined as the anti-linear map $\Hcal\to\Bcal(\Hcal,\CC)$ and is given by $x\mapsto(y\mapsto\ip{x}{y})$.
\end{definition}
\begin{lemma}\label{bra_adjoint_eq_ket}\uses{bra, ket}\lean{bra_adjoint_eq_ket}\leanok
  Given $x\in \Hcal$, we get $\bra{x}^*=\ket{x}$.
\end{lemma}
\begin{proof}\leanok
  Easy computation.
\end{proof}
\begin{corollary}\label{bra-ket}\uses{bra, ket}\lean{bra_ket_one_eq_inner}\leanok
  Given $x,y\in\Hcal$, we get $\bra{x}\circ\ket{y}(1)=\ip{x}{y}$.
\end{corollary}
\begin{proof}\leanok
  Straightforward computation.
\end{proof}
\begin{corollary}\label{unit_eq_ket_one}
  \uses{ket}
  \lean{algebraMapCLM_eq_ket_one}\leanok
  Let $\mathcal{A}$ be an algebra and a Hilbert space. Then the unit map $\eta\colon\CC\to\mathcal{A}$ (which is given by $\alpha\mapsto \alpha1$) is exactly $\ket{1}$.
\end{corollary}
\begin{proof}\leanok
  True by definition.
\end{proof}
\begin{corollary}\label{unit_adjoint_eq_bra_one}\uses{bra}\lean{algebraMapCLM_adjoint_eq_bra_one}\leanok
  The adjoint of the unit map $\eta\colon\CC\to\mathcal{A}$ in an algebra and Hilbert space $\mathcal{A}$ is $\bra{1}$.
 \end{corollary}
 \begin{proof}\uses{unit_eq_ket_one, bra_adjoint_eq_ket}\leanok
  Use Lemma \ref{bra_adjoint_eq_ket} and Corollary \ref{unit_eq_ket_one}.
 \end{proof}
 \begin{lemma}\label{linearMap_comp_ket}\uses{ket}\lean{continuousLinearMap_comp_ket}\leanok
  Let $f\in\Bcal(\Hcal_1,\Hcal_2)$ and $x\in\Hcal_1$. Then $f\circ\ket{x}=\ket{f(x)}$.
 \end{lemma}
 \begin{proof}\leanok
  Simple computation.
 \end{proof}
 \begin{lemma}\label{bra_comp_linearMap}\uses{bra}\lean{bra_comp_continuousLinearMap}\leanok
  Let $f\in\Bcal(\Hcal_1,\Hcal_2)$ and $x\in\Hcal_2$. Then $\bra{x}\circ f=\bra{f^*(x)}$.
 \end{lemma}
 \begin{proof}\leanok
  Simple computation.
 \end{proof}

\section{Ket-bras}
\begin{definition}\label{rankOne}\uses{ket, bra}\lean{rankOne}\leanok
  A \textit{ket-bra} operator $\ketbra{\cdot}{\cdot}$ is defined as the linear map from $E_2$ to the anti-linear map $E_1\to\Bcal(E_1,E_2)$ and is given by
  \begin{align*}
    x\mapsto(y\mapsto(u\mapsto\ip{y}{u}x)).
  \end{align*}
  This is exactly $\ketbra{\cdot}{\cdot}=\ket{\cdot}\,\circ\,\bra{\cdot}$.
\end{definition}
Let $E_1,E_2,E_3$ be inner product spaces over $\CC$.
So given $x\in{E_2}$ and $y\in{E_1}$, we write $\ketbra{x}{y}$ to mean the map $u\mapsto\ip{y}{u}x$.

 \begin{lemma}\label{linearMap_comp_rankOne}\uses{rankOne}\lean{ContinuousLinearMap.comp_rankOne}\leanok
  Given a linear map $T_1\in\Bcal(E_2,E_3)$ and elements $x\in E_2$, $y\in{E_1}$, we get, $T_1\circ\ketbra{x}{y}=\ketbra{T_1(x)}{y}$
 \end{lemma}
 \begin{proof}\uses{linearMap_comp_ket}\leanok
  Straightforward computation.
 \end{proof}
 
 \begin{lemma}\label{rankOne_comp_linearMap}\uses{rankOne}\lean{ContinuousLinearMap.rankOne_comp}\leanok
  Given a linear map $T_2\in\Bcal(E_3,E_1)$ and elements $x\in E_2$, $y\in E_1$, we get $\ketbra{x}{y}\circ T_2=\ketbra{x}{T_2^*(y)}$.
 \end{lemma}
 \begin{proof}\uses{bra_comp_linearMap}\leanok
  Straightforward computation.
 \end{proof}
 
 \begin{lemma}\label{rankOne_adjoint}\uses{rankOne}\lean{rankOne_adjoint}\leanok
  Given $x\in E_2$ and $y\in E_1$, we get $\ketbra{x}{y}^*=\ketbra{y}{x}$.
 \end{lemma}
 \begin{proof}\uses{bra_adjoint_eq_ket}\leanok
  Using Lemma \ref{bra_adjoint_eq_ket}.
 \end{proof}

 \begin{lemma}\label{sum_rankOne_onb_eq_id}\uses{rankOne}\lean{rankOne.sum_orthonormalBasis_eq_id}\leanok
  Given an orthonormal basis $(u_i)$ of a $\CC$-inner product space $E$, we get $\sum_i\ketbra{u_i}{u_i}=\id$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{lemma}\label{ContinuousLinearMap.centralizer}\lean{ContinuousLinearMap.commutes_with_all_iff}\leanok
  Given a Hilbert space $\Hcal$, we have ${\Bcal(\Hcal)}^\prime=\{\alpha\id:\alpha\in\CC\}$.\\
  In other words, $x\in\Bcal(\Hcal)$ commutes with all operators $y\in\Bcal(\Hcal)$ if and only if $x=\alpha\id$ for some $\alpha\in\CC$.
 \end{lemma}
 \begin{proof}\uses{rankOne_adjoint, rankOne_comp_linearMap, linearMap_comp_rankOne}\leanok
  Let $x\in\Bcal(\Hcal)$. Obviously, if $x=\alpha\id$ for some $\alpha\in\CC$, then it commutes with every other operator. Now suppose $x$ commutes with every operator in $\Bcal(\Hcal)$.
  So this means $\ketbra{a}{x^*(b)}=\ketbra{a}{b}x=x\ketbra{a}{b}=\ketbra{x(a)}{b}$ for all $a,b\in\Hcal$.
  Suppose there exists some non-zero $a\in\Hcal$, otherwise this is trivial. Then, for any $b\in\Hcal$, we have
  \[x(b)=\frac{\norm{a}^2}{\norm{a}^2}x(b)=\frac{1}{\norm{a}^2}\ketbra{x(b)}{a}(a)=\frac{1}{\norm{a}^2}\ketbra{b}{x^*(a)}(a)=\frac{\ip{x^*(a)}{a}}{\norm{a}^2}b.\]
  Thus $x=\alpha\id$ where $\alpha=\ip{x^*(a)}{a}/\norm{a}^2$.
 \end{proof}

 \begin{proposition}\label{colinear_of_rankOne_self_eq_rankOne_self}\uses{rankOne}\lean{colinear_of_rankOne_self_eq_rankOne_self}\leanok
  Let $\Hcal$ be a Hilbert space, and let $x,y\in\Hcal$. Then if $\ketbra{x}{x}=\ketbra{y}{y}$, then there exists some $0\neq\alpha\in\CC$ such that $x=\alpha{y}$ (i.e., they are co-linear).
 \end{proposition}
 \begin{proof}\leanok
  Suppose $\ketbra{x}{x}=\ketbra{y}{y}$. Then it is clear that we get $x=0$ if and only if $y=0$. So we assume $x\neq0$ (and so $y\neq0$), otherwise this is trivial.
  Then we have \[\norm{x}^2x=\ketbra{x}{x}(x)=\ketbra{y}{y}(x)=\ip{y}{x}y.\]
  And as $x\neq0$, we get $x=\dfrac{\ip{y}{x}}{\norm{x}^2}y$. We have $\ip{y}{x}\neq0$ (otherwise, this would mean $x=0$ which is a contradiction). Thus we can let $\alpha=\ip{y}{x}/\norm{x}^2\neq0$ such that $x=\alpha{y}$.
 \end{proof}


 \begin{lemma}\label{LinearMap.isPositive_iff_eq_sum_rankOne}\uses{rankOne}\lean{LinearMap.isPositive_iff_eq_sum_rankOne}\leanok
  Given a finite-dimensional inner product space $E$ over $\CC$ and $T\in\Bcal(E)$, we get\\
  \hspace*{0.5cm}$T$ is positive semi-definite $\LRa$ $T=\sum_i\ketbra{v_i}{v_i}$ for some tuple $(v_i)$ in $E$.
 \end{lemma}
 \begin{proof}\uses{sum_rankOne_onb_eq_id}\leanok {\ }
 \begin{description}
  \item[$(\tto)$]
   Suppose $0\leq{T}$. We use the spectral theorem and let $(v_i)$ be the eigenbasis of $T$ in $E$ with corresponding eigenvalues $(\lambda_i)$. Note that, as $0\leq{T}$, we also get each $0\leq\lambda_i$. So then let each $x_i=\sqrt{\lambda_i}u_i$. Then we have $\sum_i\ketbra{x_i}{x_i}=\sum_i\sqrt{\lambda_i}\overline{\sqrt{\lambda_i}}\ketbra{u_i}{u_i}=\sum_i\lambda_i\ketbra{u_i}{u_i}=T$, where the last equality comes from Corollary \ref{sum_rankOne_onb_eq_id}.
  \item[$(\ott)$]
   Suppose we have some tuple $(v_i)$ in $E$ such that $T=\sum_i\ketbra{v_i}{v_i}$. Then, for any $x\in{E}$, we get
   $\ip{x}{T(x)}=\sum_i\ip{x}{v_i}\ip{v_i}{x}=\sum_i\abs{\ip{x}{v_i}}^2\geq0$.
   Thus $T$ is positive semi-definite.
 \end{description}
 \end{proof}

 Given an orthonormal basis $b=(b_i)$ of a finite-dimensional Hilbert space $\Hcal$, we define $R_b$ to be the linear isomorphism $\Hcal\cong\CC^{\dim\Hcal}$ given by $R_b(x)_i=\ip{b_i}{x}$ with its inverse given by $x\mapsto\sum_ix_ib_i$.
 \begin{lemma}\label{repr_adjoint}\lean{OrthonormalBasis.repr_adjoint'}\leanok
  Let $e=(e_i)$ be an orthonormal basis of a finite-dimensional Hilbert space $\Hcal$. Then $R_e^*=R_e^{-1}$.
 \end{lemma}
 \begin{proof}\leanok
  Let $x\in\Hcal$ and $y\in\CC^{\dim\Hcal}$. Then we compute,
  \begin{align*}
   \ip{x}{R_e^*(y)}_{\Hcal} &= \ip{R_e(x)}{y}_{\CC^{\dim\Hcal}} = \sum_i\ip{R_e(x)_i}{y_i}_{\CC} = \sum_i\ip{\ip{e_i}{x}_{\Hcal}}{y_i}_{\CC}\\
   &= \sum_i\ip{x}{e_i}_{\Hcal}y_i = \sum_i\ip{x}{y_ie_i}_{\Hcal}=\ip{x}{R_e^{-1}(y)}_{\Hcal}.
  \end{align*}
  Thus $R_e^*=R_e^{-1}$.
 \end{proof}
 Given orthonormal bases $b=(b_i)$ and $c=(c_j)$ of Hilbert spaces $\Hcal_1,\Hcal_2$, then we let $\mathcal{M}$ denote the identification from $\Bcal(\Hcal_1,\Hcal_2)$ to $M_{\dim\Hcal_2,\dim\Hcal_1}$, which is given by $\Mcal_{b,c}(T)_{kp}=\ip{c_k}{T(b_p)}$.
 \begin{lemma}\label{rankOne_toMatrix}\uses{rankOne}\lean{rankOne_toMatrix_of_onb}\leanok
  Given orthonormal bases $b=(b_i)$ and $c=(c_j)$ of finite-dimensional Hilbert spaces $\Hcal_1,\Hcal_2$, and elements $x\in\Hcal_1$ and $y\in\Hcal_2$, we have $\mathcal{M}_{c,b}(\ketbra{x}{y})=R_b(x){R_c(y)}^*$.
 \end{lemma}
 \begin{proof}\leanok
  For any $i\in[\dim\Hcal_1],j\in[\dim\Hcal_2]$, we compute,
  \[\mathcal{M}_{c,b}(\ketbra{x}{y})_{ij}=\ip{b_i}{\ketbra{x}{y}(c_j)}=\ip{b_i}{x}\ip{y}{c_j}=R_b(x)_i\overline{R_c(y)_j}=\left(R_b(x){R_c(y)}^*\right)_{ij}.\]
  Thus $\mathcal{M}_{c,b}(\ketbra{x}{y})=R_b(x){R_c(y)}^*$.
 \end{proof}

\chapter{Star-preserving maps}
 In this section, we define what it means for a linear map to be \textit{real} (also known as \textit{star-preserving}) on Hilbert spaces $\Hcal_1,\Hcal_2$.
 
 \begin{definition}\label{LinearMap.IsReal}\lean{LinearMap.IsReal}\leanok
  We say $A\in\Bcal(\Hcal_1,\Hcal_2)$ is \textit{real} (\textit{star-preserving}) when $A(a^*)={A(a)}^*$ for each $a\in\Hcal_1$.
 \end{definition}
 
 \begin{definition}\label{LinearMap.real}\lean{LinearMap.real}\leanok
  We define the map $\cdot^{\operatorname{r}}$ as the self-invertible anti-linear automorphism $(\Hcal_1\to\Hcal_2)\cong(\Hcal_1\to\Hcal_2)$ given by
  \[A\mapsto(a\mapsto{A(a^*)}^*).\]
 \end{definition}

 \begin{lemma}\label{LinearMap.isReal_iff}\uses{LinearMap.IsReal, LinearMap.real}\lean{LinearMap.isReal_iff}\leanok
  Let $A\in\Bcal(\Hcal_1,\Hcal_2)$. Then $A$ is real if and only if $A^{\operatorname{r}}=A$.
 \end{lemma}
 \begin{proof}\leanok
  Clearly $A^{\operatorname{r}}(x)={A(x^*)}^*=A(x)$ if and only if $A(x^*)={A(x)}^*$ for all $x\in\Hcal$, which means $A$ is real.
 \end{proof}

 \begin{lemma}\label{LinearMap.real_comp}\uses{LinearMap.real}\lean{LinearMap.real_comp}\leanok
  When $f\in\Bcal(\Hcal_1,\Hcal_2)$ and $g\in\Bcal(\Hcal_3,\Hcal_1)$, then we get ${(f\circ g)}^{\operatorname{r}}={f^{\operatorname{r}}}\circ{{g^{\operatorname{r}}}}$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{lemma}\label{TensorProduct.map_real}\uses{LinearMap.real}\lean{TensorProduct.map_real}\leanok
  Given Hilbert spaces $\Hcal_1,\Hcal_2,\Hcal_3,\Hcal_4$, and linear maps $x\colon\Hcal_1\to\Hcal_2$ and $y\colon\Hcal_3\to\Hcal_4$, we clearly get $\real{(x\otimes y)}=\real{x}\otimes\real{y}$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{proposition}\label{LinearMap.real.spectrum}\uses{LinearMap.real}
  \lean{LinearMap.real.spectrum}\leanok
  Given $A\in\Bcal(\Hcal)$, we get $\Spectrum(\real{A})=\overline{\Spectrum(A)}$.\\
  In fact, $x\in\ker(A-\lambda\id)$ if and only if $x^*\in\ker(\real{A}-\bar{\lambda}\id)$.
 \end{proposition}
 \begin{proof}\leanok
  For any $x\in\Hcal$, we have $\real{A}(x^*)={A(x)}^*$. So if $x$ is an eigenvector of $A$ with eigenvalue $\lambda$, then clearly $\real{A}(x^*)=\bar{\lambda}x^*$, so $x^*$ is an eigenvector of $\real{A}$ with eigenvalue $\bar{\lambda}$.
  If, on the other hand, $x^*$ is an eigenvector of $\real{A}$ with eigenvalue $\bar{\lambda}$, then ${A(x)}^*=\bar{\lambda}x^*$, and so $A(x)=\lambda x$, which means $x$ is an eigenvector of $A$ with eigenvalue $\lambda$.
 \end{proof}

\chapter{The inner product}

 \section{On $M_n$}

  \begin{definition}\label{Dual.matrix}\lean{Module.Dual.matrix}\leanok
   Given a linear functional $\phi\colon M_n \to \CC$, we define $\phi_Q=\sum_{i,j}\phi(e_{ij})e_{ji}$.
  \end{definition}

  \begin{lemma}\label{dual_eq_trace}\uses{Dual.matrix}\lean{Module.Dual.apply}\leanok
   Given a linear functional $\phi\colon M_n\to\CC$, we get $\phi$ is given by $x\mapsto\Tr(\phi_Q \,x)$.
  \end{lemma}
  \begin{proof}\leanok
   Straightforward computation.
  \end{proof}

  \begin{definition}\label{LinearMap.IsPosMap}\lean{LinearMap.IsPosMap}\leanok
   Given C$^*$-algebras $A,C$, we say a linear map $f\colon A \to C$ is \textit{positive} when $0\leq f(a)$ for all $0\leq a$. In other words, $f$ maps positive elements in $A$ to positive elements in $C$.
  \end{definition}

  As any matrix $x\in{M_n}$ is positive if and only if there exists some $y\in M_n$ such that $x=y^*y$, we get that a linear functional $f$ on $M_n$ is a \textit{positive map} when $0\leq{f(x^*x)}$ for any matrix $x\in{M_n}$.

  \begin{lemma}\label{Dual.isPosMap_iff_of_matrix}\uses{Dual.matrix, LinearMap.IsPosMap}\lean{Module.Dual.isPosMap_iff_of_matrix}\leanok
   Given a linear functional $\phi$ on $M_n$, we have,\\
   \hspace*{0.5cm}$\phi$ is positive $\,\LRa\,$ $0\leq\phi_Q$.\\
   Here, $\phi_Q$ is the matrix of $\phi$ defined in Definition \ref{Dual.matrix}.
  \end{lemma}
  \begin{proof}\uses{dual_eq_trace, LinearMap.isPositive_iff_eq_sum_rankOne}\leanok
   By Lemma \ref{dual_eq_trace} we have $\phi(x)=\Tr(\phi_Q\, x)$ for all $x\in{M_n}$.
   \begin{description}
    \item[$(\tto)$]
     Suppose $\phi$ is positive. By Lemma \ref{LinearMap.isPositive_iff_eq_sum_rankOne}, we get $0\leq\sum_i\phi(x_ix_i^*)$ for any tuple $(x_i)$ in $\CC^n$. So then for any $x\in\CC^n$, we have $0\leq\phi(xx^*)=\Tr(\phi_Q\, xx^*)=x^*\phi_Q\, x$, which means $\phi_Q$ is positive semi-definite.
    \item[$(\ott)$]
     Suppose $\phi_Q$ is positive semi-definite. Then since $\phi_Q$ is positive semi-definite, we have $\phi_Q=\phi_Q^{1/2}\phi_Q^{1/2}$, where $\phi_Q^{1/2}$ is also positive semi-definite (and so is self-adjoint). So for any $x\in{M_n}$, we have $\phi(x^*x)=\Tr(\phi_Q\, x^*x)=\Tr\left({(x\phi_Q^{1/2})}^*(x\phi_Q^{1/2})\right)\geq0$.
   \end{description}
   Thus $\phi$ is a positive map if and only if our matrix $\phi_Q$ is positive semi-definite.
  \end{proof}

  \begin{proposition}\label{Dual.isReal_iff}\uses{LinearMap.IsReal, Dual.matrix}\lean{Module.Dual.isReal_iff}\leanok
   Given a linear functional $\phi\colon{M_n}\to\CC$, we get $\phi$ is real (star-preserving) if and only if $\phi_Q$ is self-adjoint.\\
   Here, $\phi_Q$ is the matrix given by $\phi$ defined in Definition \ref{Dual.matrix}.
  \end{proposition}
  \begin{proof}\uses{dual_eq_trace}\leanok {\ }
   \begin{description}
    \item[$(\tto)$]
     Suppose $\phi$ is star-preserving, i.e., $\phi(x^*)=\overline{\phi(x)}$ for all $x\in{M_n}$.
     We let $x\in{M_n}$, and compute using Lemma \ref{dual_eq_trace},
     \[\Tr(\phi_Q\, x^*)=\phi(x^*)=\overline{\phi(x)}=\overline{\Tr(\phi_Q\, x)}=\Tr(x^*\phi_Q^*),\]
     And so $\phi_Q=\phi_Q^*$.
    \item[$(\ott)$]
     Suppose $\phi_Q$ is self-adjoint. Using Lemma \ref{dual_eq_trace}, $\phi$ is given by $x\mapsto\Tr(\phi_Q\, x)$.
     And so for any $x\in{M_n}$, we get $\phi(x^*)=\Tr(\phi_Q\, x^*)=\Tr({(x\phi_Q)}^*)=\overline{\Tr(x\phi_Q)}=\overline{\phi(x)}$.
     Thus, $\phi$ is real.
   \end{description}
  \end{proof}

\begin{corollary}\label{Matrix.isPosSemidef_and_invertible_iff_isPosDef}\lean{Matrix.PosSemidef.invertible_iff_posDef}\leanok
  If $A\in{M_n}$. Then\\
  \hspace*{0.5cm}$0\leq{A}$ and is invertible $\,\LRa\,$ $A$ is positive-definite.
 \end{corollary}
 \begin{proof}\leanok {\ }
  \begin{description}
   \item[$(\tto)$]
    Suppose $0\leq{A}$ and $A=A^{1/2}A^{1/2}$ is invertible. Then $A^{1/2}$ is also invertible and positive semi-definite. Let $v\in\CC^n$ be non-zero.
    Then, we compute,
    \[\ip{v}{Av}=\ip{v}{A^{1/2}A^{1/2}v}=\ip{A^{1/2}v}{A^{1/2}v}>0,\]
    since $A^{1/2}v\neq0$ (as $A^{1/2}$ is invertible). Note that, in the second equality, we use the self-adjointed-ness of $A^{1/2}$ since it is positive semi-definite. So we are done.
   \item[$(\ott)$]
    Suppose $0<A$. Then obviously $0\leq{A}$, so we only need to check if it is invertible. Suppose the contrary, i.e., $A$ is not invertible. Then there exists a non-zero $v\in\CC^n$ such that $Av=0$. But then, by the hypothesis, we get $0<\ip{v}{Av}=0$, which is a contradiction. Thus $A$ is invertible.
  \end{description}
 \end{proof}


\begin{lemma}\label{PosDef.trace_conjTranspose_mul_self_eq_zero_iff}\lean{Matrix.PosDef.trace_conjTranspose_hMul_self_eq_zero}\leanok
  Given a positive definite matrix $Q\in{M_n}$, we have $\Tr(Qx^*x)=0$ if and only if $x=0$ for any $x\in{M_n}$.
 \end{lemma}
 \begin{proof}\uses{Matrix.isPosSemidef_and_invertible_iff_isPosDef}\leanok
  We have $\Tr\left({(xQ^{1/2})}^*(xQ^{1/2})\right)=\Tr(Qx^*x)=0$ if and only if $xQ^{1/2}=0$. As $Q^{1/2}$ is positive definite, we get it is also invertible by Corollary \ref{Matrix.isPosSemidef_and_invertible_iff_isPosDef}, and so $xQ^{1/2}=0$ if and only if $x=0$. And so we are done.
 \end{proof}

  \begin{definition}\label{Dual.IsFaithful}\lean{Module.Dual.IsFaithful}\leanok
   A linear functional $f$ on $A$ is said to be \textit{faithful} if $f(x^*x)=0$ if and only if $x=0$ for all $x\in A$.
  \end{definition}

  \begin{proposition}\label{Dual.isFaithfulPosMap_iff}
    \uses{LinearMap.IsPosMap, Dual.IsFaithful, Dual.matrix}
    \lean{Module.Dual.isFaithfulPosMap_iff_of_matrix}\leanok
    Given a linear functional $\phi\colon{M_n}\to\CC$, we have\\
    \hspace*{0.5cm}$\phi$ is a positive and faithful map $\,\LRa\,$ $\phi_Q$ is positive-definite.\\
    Again, $\phi_Q$ is the matrix given by $\phi$ defined in Definition \ref{Dual.matrix}.
   \end{proposition}
   \begin{proof}\uses{dual_eq_trace, Dual.isPosMap_iff_of_matrix, PosDef.trace_conjTranspose_mul_self_eq_zero_iff}\leanok
    By Lemma \ref{dual_eq_trace}, we have $\phi$ is given by $x\mapsto\Tr(\phi_Q\, x)$, and by Lemma \ref{Dual.isPosMap_iff_of_matrix}, we know $\phi$ is positive if and only if $0\leq\phi_Q$.
    So we need to show that faithfulness of a positive linear functional is equivalent to $\phi_Q$ being positive definite.
    \begin{description}
     \item[$(\tto)$]
      Suppose $\phi$ is faithful and positive.
      So we have $\phi(x)=0$ if and only if $x=0$ for any positive semi-definite matrix $x\in{M_n}$.
      Let $0\neq{x}\in\CC^n$. Then we have $xx^*\neq0$ as $x\neq0$. This means, by faithfulness and positivity of $\phi$ we get $\phi(xx^*)\neq0$ as $xx^*$ is a non-zero positive semi-definite matrix. And so $0<\phi(xx^*)=\Tr(\phi_Q\, xx^*)=x^*\phi_Q\, x$, which means $\phi_Q$ is positive definite.
     \item[$(\ott)$]
      Suppose $\phi_Q$ is positive definite. Then for any $x\in{M_n}$, we get $\phi(x^*x)=\Tr(\phi_Q\, xx^*)=0$ if and only if $x=0$ using Lemma \ref{PosDef.trace_conjTranspose_mul_self_eq_zero_iff}.
    \end{description}
    Thus $\phi$ is a faithful and positive linear functional if and only if the matrix $\phi_Q$ is positive definite.
   \end{proof}

  \begin{theorem}\label{Dual.isFaithfulPosMap_tfae}
   \uses{LinearMap.IsPosMap, Dual.IsFaithful}
   \lean{Module.Dual.isFaithfulPosMap_of_matrix_tfae}
   Given a linear functional $\phi\colon{M_n}\to\CC$, then the following are equivalent,
   \begin{enumerate}[label=(\roman*)]
    \item $\phi$ is positive and faithful,
    \item $\phi_Q$ is pos-def and $\forall{x}\in{M_n}:\phi(x)=\Tr(Qx)$,
    \item $M_n\times{M_n}\to\CC\colon(x,y)\mapsto\phi(x^*y)$ defines an inner product on $M_n$.
   \end{enumerate}
  \end{theorem}
  \begin{proof}\uses{dual_eq_trace, Dual.isReal_iff, Dual.isFaithfulPosMap_iff}\leanok
   The equivalence of the first and second parts is from Proposition \ref{Dual.isFaithfulPosMap_iff}.
   
   For any $x,y\in{M_n}$, let $\ip{x}{y}_\phi=\phi(x^*y)$.
   Then, clearly,
   \[\ip{x}{\alpha{y}+\beta{z}}_\phi=\phi(x^*(\alpha{y}+\beta{z}))=\alpha\phi(x^*y)+\beta\phi(x^*z)=\alpha\ip{x}{y}_\phi+\beta\ip{x}{z}_\phi,\]
   by linearity of $\phi$, for any $x,y,z\in{M_n}$ and $\alpha,\beta\in\CC$.
   \begin{description}
    \item[$(\tto)$]
     If $\phi$ is faithful, we have $\ip{x}{x}_\phi=\phi(x^*x)=0$ if and only if $x=0$ for any $x\in{M_n}$.
     And $\phi$ is positive if and only if $0\leq\ip{x}{x}_\phi$ for any $x\in{M_n}$. So if $\ip{\cdot}{\cdot}_\phi$ defines an inner product on $M_n$, then we get $\phi$ is faithful and positive. So it remains to show that, given $\phi$ is a faithful and positive linear functional, we get $\overline{\ip{x}{y}_\phi}=\ip{y}{x}_\phi$ for any $x,y\in{M_n}$.
    \item[$(\ott)$]
     Suppose $\phi$ is faithful and positive. By Proposition \ref{Dual.isFaithfulPosMap_iff}, we get the matrix $\phi_Q$ is positive definite (and so is self-adjoint). Using Proposition \ref{Dual.isReal_iff}, we get $\phi$ is real, and so, for any $x,y\in{M_n}$, we get, $\overline{\ip{x}{y}_\phi}=\overline{\phi(x^*y)}=\phi(y^*x)=\ip{y}{x}_\phi$.
     Therefore, $\ip{\cdot}{\cdot}_\phi\colon(x,y)\mapsto\phi(x^*y)$ is a well-defined inner product on $M_n$.
   \end{description}
  \end{proof}

\section{On $\bigoplus_iM_{n_i}$}

\begin{definition}\label{PiMat.InnerProductSpace}
  \uses{Dual.isFaithfulPosMap_tfae, LinearMap.IsPosMap, Dual.IsFaithful}
  \lean{Module.Dual.pi.InnerProductSpace}\leanok
  For each $i$, we fix a faithful and positive linear functional $\psi_i$ on $M_{n_i}$, and we let $Q_i\in{M_{n_i}}$ denote the positive definite matrix such that $\psi_i\colon x\mapsto\Tr(Q_ix)$ (so each $Q_i=\sum_{j,k}\psi_i(e_{jk})e_{kj}$) -- see Proposition \ref{Dual.matrix}.

  Let $\psi$ be a faithful positive linear functional on $\bigoplus_iM_{n_i}$ given by $\psi=\sum_i\psi_i\circ p_i$, where each $p_i$ is the projection map $\bigoplus_jM_{n_j}\to M_{n_i}$, and we let $Q=\bigoplus_iQ_i$. So then, given $x\in\big_i{M_{n_i}}$, we get $\psi(x)=\Tr(Q x)$, where $\Tr$ here is defined by the sum of the diagonals in each matrix block.

  By Theorem \ref{Dual.isFaithfulPosMap_tfae}, we define the inner product on each $M_{n_i}$ by
  \[\ip{x}{y}_{\psi_i}=\psi_i(x^*y)=\Tr(\Q_ix^*y),\]
  for all $x,y\in{M_{n_i}}$. We denote $(M_{n_i},\psi_i)$ to be the Hilbert space given by this inner product.\\
  We define the inner product on $\bigoplus_iM_{n_i}$ by \[\ip{x}{y}_{\psi}=\psi(x^*y)=\Tr(\Q x^*y),\] for all $x,y\in\bigoplus_i{M_{n_i}}$, where $\Tr$ here is defined as the sum of the diagonals in each matrix block.
 \end{definition}

 \begin{proposition}\label{Dual.IsFaithfulPosMap.adjoint_eq_unit}
  \uses{PiMat.InnerProductSpace}
  \lean{Module.Dual.pi.IsFaithfulPosMap.adjoint_eq}\leanok
  The adjoint of $psi$ on $(\bigoplus_iM_{n_i},\psi)$ and $\CC$ is given by $\CC\to{B}\colon{x\mapsto{x1}}$. In other words, $\psi^*=\ket{1}$.
 \end{proposition}
 \begin{proof}\leanok
  For any $x\in\CC$ and $y\in\bigoplus_i{M_{n_i}}$, we have,
  \[\ip{\psi^*(x)}{y}_{\psi}=\ip{x}{\psi(y)}_\CC=\overline{x}\psi(y)=\overline{x}\ip{1}{y}_{\psi}=\ip{x1}{y}_{\psi}.\]
  Thus $\psi^*(x)=x1$ for any $x\in\CC$.
 \end{proof}

 \begin{proposition}\label{PiMat.onb}\uses{PiMat.InnerProductSpace}
  \lean{Module.Dual.pi.IsFaithfulPosMap.orthonormalBasis}\leanok
  We get $\left[\iota_s(e_{ij}Q_s^{-1/2})_{i,j=1}^{n_s}\right]_{s=1}^{\mathfrak{K}}$ is an orthonormal basis of $(\bigoplus_iM_{n_i},\psi)$.\\
  Here, $Q=\psi_Q$ from Proposition \ref{Dual.matrix}.
 \end{proposition}
 \begin{proof}
 \end{proof}

 Recall that, given an orthonormal basis $f=(f_i)$ on a Hilbert space $\Hcal$, we let $R_f$ be the linear isomorphism $\Hcal \cong \CC^{\dim\Hcal}$ given by $R_f(x)_i=\ip{f_i}{x}$.
 \begin{proposition}\label{PiMat.onb_repr}\uses{PiMat.onb}\lean{basis_repr_apply'}\leanok
  Let $f$ be the orthonormal basis from Proposition \ref{PiMat.onb}.
  Then for $x\in\bigoplus_iM_{n_i}$, we get $R_f(x)_{s,ij}=(xQ^{1/2})_{s,ij}$.\\
  Here, $Q=\psi_Q$ from Proposition \ref{Dual.matrix}.
 \end{proposition}
 \begin{proof}\uses{PiMat.InnerProductSpace}
 \end{proof}

\chapter{Algebra and co-algebras}

 Recall that an algebra $\mathcal{A}$ is given by a multiplication map $m\colon \mathcal{A}\otimes\mathcal{A}\to\mathcal{A}$ and a unit map $\eta\colon \CC\to\mathcal{A}$, with associativity $m(m\otimes\id)=m(\id\otimes\,m)$ and the property $m(\eta\otimes\id)=\id=m(\id\otimes\,\eta)$. We say $(\mathcal{A},m,\eta)$ is an algebra when those properties are satisfied.

 \begin{corollary}\uses{ket}\lean{algebraMapCLM_eq_ket_one}\leanok
  When an algebra $(\mathcal{A},m,\eta)$ is also a Hilbert space, we get $\eta=\ket{1}$.
 \end{corollary}
 \begin{proof}\leanok
  True by definition.
 \end{proof}

 Also recall that we say $\mathcal{A}$ is a \textit{co-algebra} when it has a co-multiplication map $\mu\colon\mathcal{A}\to\mathcal{A}\otimes\mathcal{A}$ and a co-unit map $\varpi\colon\mathcal{A}\to\CC$ such that co-associativity is satisfied, i.e., $(\mu\otimes\id)\mu=(\id\otimes\,\mu)\mu$, and the property $(\varpi\otimes\id)\mu=\id=(\id\otimes\,\varpi)\mu$ is satisfied.
 We say $(\mathcal{A},\mu,\varpi)$ is a co-algebra when those properties are satisfied.

 \begin{theorem}[the Frobenius equations]\label{Frobenius_equations}\lean{lTensor_mul_comp_rTensor_comul_of}\leanok
  Given an algebra and co-algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, then if
  \[(\id\otimes\,m)(\mu\otimes\id)=(m\otimes\id)(\id\otimes\,\mu),\]
  then we get the following equations (the Frobenius equations),
  \[(\id\otimes\,m)(\mu\otimes\id)=\mu m=(m\otimes\id)(\id\otimes\,\mu).\]
 \end{theorem}
 \begin{proof}\leanok
  \begin{align*}
   (m\otimes\id)(\id\otimes\,\mu) &= (m\otimes\id)((\varpi\otimes\id)\mu\otimes\mu) &\text{by (counit.id)}\\
   &= (m\otimes\id)(\varpi\otimes\id^{\otimes3})\mu^{\otimes2}\\
   &= (m(\varpi\otimes\id^{\otimes2})\otimes\id)\mu^{\otimes2}\\
   &= ((\id_\CC\otimes\,m)(\varpi\otimes\id^{\otimes2})\otimes\id)\mu^{\otimes2}\\
   &= ((\varpi\otimes\id)(\id\otimes\,m)\otimes\id)\mu^{\otimes2}\\
   &= (\varpi\otimes\id^{\otimes2})(\id\otimes\,m\otimes\id)(\mu\otimes\id^{\otimes2})(\id\otimes\,\mu)\\
   &= (\varpi\otimes\id^{\otimes2})((\id\otimes\,m)(\mu\otimes\id)\otimes\id)(\id\otimes\,\mu)\\
   &= (\varpi\otimes\id^{\otimes2})((m\otimes\id)(\id\otimes\,\mu)\otimes\id)(\id\otimes\,\mu) &\text{by hyp}\\
   &= (\varpi\otimes\id^{\otimes2})(m\otimes\id^{\otimes2})(\id\otimes\,(\mu\otimes\id)\mu)\\
   &= (\varpi m\otimes\id^{\otimes2})(\id\otimes\,(\id\otimes\mu)\mu) &\text{by (comul.assoc)}\\
   &= (\varpi\otimes\id^{\otimes2})(m\otimes\id^{\otimes2})(\id^{\otimes2}\otimes\mu)(\id\otimes\,\mu)\\
   &= (\varpi\otimes\id^{\otimes2})(\id\otimes\,\mu)(m\otimes\id)(\id\otimes\,\mu)\\
   &= (\varpi\otimes\id^{\otimes2})(\id\otimes\,\mu)(\id\otimes\,m)(\mu\otimes\id) &\text{by hyp}\\
   &= (\varpi\otimes\id^{\otimes2})(\id\otimes\,\mu m)(\mu\otimes\id)\\
   &= (\id_\CC\otimes\,\mu m)(\varpi\otimes\id^{\otimes2})(\mu\otimes\id)\\
   &= \mu m((\varpi\otimes\id)\mu\otimes\id)\\
   &= \mu m(\id\otimes\,\id) &\text{by (counit.id)}\\
   &= \mu m.
  \end{align*}
 \end{proof}

 \begin{definition}\label{FrobeniusAlgebra}\lean{FrobeniusAlgebra}\leanok
  We say an algebra and co-algebra $(\mathcal{A},m,\eta,\mu,\varpi)$ is a \textit{Frobenius algebra} when it satisfies the Frobenius equation condition,
  \[(m\otimes\id)(\id\otimes\,\mu)=(\id\otimes\,m)(\mu\otimes\id).\]
 \end{definition}

 \begin{corollary}\label{rTensor_mul_comp_lTensor_comul_unit_eq_comul}
  \uses{FrobeniusAlgebra, Frobenius_equations}
  \lean{FrobeniusAlgebra.rTensor_mul_comp_lTensor_comul_unit_eq_comul}\leanok
  Given a Frobenius algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, we get,
  \[(m\otimes\id)(\id\otimes\,\mu\eta)=\mu.\]
 \end{corollary}
 \begin{proof}\leanok
  By Theorem \ref{Frobenius_equations} and definition.
 \end{proof}

 \begin{corollary}\label{lTensor_mul_comp_rTensor_comul_unit}
  \uses{FrobeniusAlgebra, Frobenius_equations}
  \lean{FrobeniusAlgebra.lTensor_mul_comp_rTensor_comul_unit}
  Given a Frobenius algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, we get,
  \[(\id\otimes\,m)(\mu\unit\otimes\id)=\mu.\]
 \end{corollary}
 \begin{proof}\leanok
  By Theorem \ref{Frobenius_equations} and definition.
 \end{proof}

 \begin{corollary}\label{lTensor_counit_mul_comp_rTensor_comul}
  \uses{lTensor_mul_comp_rTensor_comul_unit}
  \lean{FrobeniusAlgebra.lTensor_counit_mul_comp_rTensor_comul}\leanok
  Given a Frobenius algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, we get,
  \[(\id\otimes\,\varpi m)(\mu\otimes\id)=m.\]
 \end{corollary}
 \begin{proof}\leanok
  Use Corollary \ref{lTensor_mul_comp_rTensor_comul_unit}.
 \end{proof}
 \begin{corollary}\label{rTensor_counit_mul_comp_lTensor_comul}
  \uses{rTensor_mul_comp_lTensor_comul_unit_eq_comul}
  \lean{FrobeniusAlgebra.rTensor_counit_mul_comp_lTensor_comul}\leanok
  Given a Frobenius algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, we get,
  \[(\varpi m\otimes\id)(\id\otimes\,\mu)=m.\]
 \end{corollary}
 \begin{proof}\leanok
  Use Corollary \ref{rTensor_mul_comp_lTensor_comul_unit_eq_comul}.
 \end{proof}

 The following two results are known as the ``snake equations''.
 \begin{corollary}\label{rTensor_counit_mul_comp_lTensor_comul_unit}
  \uses{rTensor_counit_mul_comp_lTensor_comul}
  \lean{FrobeniusAlgebra.rTensor_counit_mul_comp_lTensor_comul_unit}\leanok
  Given a Frobenius algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, we get,
  \[(\varpi m\otimes\id)(\id\otimes\,\mu\eta)=\id.\]
 \end{corollary}
 \begin{proof}\leanok
  Use Corollary \ref{rTensor_counit_mul_comp_lTensor_comul}.
 \end{proof}
 \begin{corollary}\label{lTensor_counit_mul_comp_rTensor_comul_unit}
  \uses{lTensor_counit_mul_comp_rTensor_comul}
  \lean{FrobeniusAlgebra.lTensor_counit_mul_comp_rTensor_comul_unit}\leanok
  Given a Frobenius algebra $(\mathcal{A},m,\eta,\mu,\varpi)$, we get,
  \[(\id\otimes\,\varpi m\otimes)(\mu\eta\otimes\id)=\id.\]
 \end{corollary}
 \begin{proof}\leanok
  Use Corollary \ref{lTensor_counit_mul_comp_rTensor_comul}.
 \end{proof}

\section{Finite-dimensional algebras}
 
 \begin{proposition}\label{Coalgebra.ofFiniteDimensionalHilbertAlgebra}
  \lean{Coalgebra.ofFiniteDimensionalHilbertAlgebra}\leanok
  Let $(\mathcal{A},m,\eta)$ be a finite-dimensional algebra and Hilbert space. Then we can form a co-algebra by letting $m^*$ be the co-multiplication and $\eta^*$ be the co-unit.
 \end{proposition}
 \begin{proof}\leanok {\ }
  \begin{description}
   \item[comul\_assoc:]
    We have the following equivalences,
    \begin{align*}
      (m^*\otimes\id)m^*=(\id\otimes\,m^*)m^* &\LRa {(m(m\otimes\id))}^*={(m(\id\otimes\,m)}^*\\
      &\LRa m(m\otimes\id)=m(\id\otimes\,m),
    \end{align*}
    which is true since $\mathcal{A}$ is an algebra.
   \item[counit\_comul\_id:]
    Similarly, taking adjoints, we get
    \begin{align*}
     &\, (\eta^*\otimes\id)m^*=\id=(\id\otimes\,\eta^*)m^*
     \,\LRa\, m(\eta\otimes\id)=\id=m(\id\otimes\,\eta),
    \end{align*}
    which is true since $\mathcal{A}$ is an algebra.
  \end{description}
 \end{proof}
 
 \begin{lemma}\label{counit_eq_bra_one}
  \uses{Coalgebra.ofFiniteDimensionalHilbertAlgebra}
  \lean{Coalgebra.counit_eq_bra_one}\leanok
  Let $(\mathcal{A},m,\eta)$ be a finite-dimensional algebra and Hilbert space. Then the counit is exactly $\bra{1}$.
 \end{lemma}
 \begin{proof}\uses{unit_adjoint_eq_bra_one}\leanok
  By definition and Lemma \ref{unit_adjoint_eq_bra_one}.
 \end{proof}

 \begin{proposition}\label{isAlgHom_iff_adjoint_isCoalgHom}
  \uses{Coalgebra.ofFiniteDimensionalHilbertAlgebra}
  \lean{LinearMap.isAlgHom_iff_adjoint_isCoalgHom}\leanok
  Let $(\mathcal{A}_1,m_1,\eta_1),(\mathcal{A}_2,m_2,\eta_2)$ be finite-dimensional algebras and Hilbert spaces, and let $f\colon\mathcal{A}_1\to\mathcal{A}_2$ be a linear map. Then $f$ is an algebra homomorphism if and only if $f^*$ is a co-algebra homomorphism.
 \end{proposition}
 \begin{proof}\leanok
  \begin{align*}
   f^*\text{ is a co-algebra hom} &\LRa (f^*\otimes f^*)\circ m_2^*=m_1^*\circ f^* \text{ and }\eta_1^*\circ f^*=\eta_2^*\\
   &\LRa m_2\circ(f\otimes f)=f\circ m_1\text{ and }f\circ\eta_1=\eta_2\\
   &\LRa f\text{ is an algebra hom}.
  \end{align*}
 \end{proof}
