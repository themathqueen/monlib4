\chapter{Ket-bra operators}

\section{Kets and bras}
\begin{definition}\label{ket}\lean{ket}\leanok
  A \textit{ket} operator $\ket{\cdot}$ on a Hilbert space $\Hcal$ is defined as the linear map $\Bcal(\Hcal,\Bcal(\CC,\Hcal))$ and is given by $x\mapsto(\alpha\mapsto\alpha x)$.
\end{definition}
\begin{definition}\label{bra}\lean{bra}\leanok
  A \textit{bra} operator $\bra{\cdot}$ on a Hilbert space $\Hcal$ is defined as the anti-linear map $\Hcal\to\Bcal(\Hcal,\CC)$ and is given by $x\mapsto(y\mapsto\ip{x}{y})$.
\end{definition}
\begin{lemma}\label{bra_adjoint_eq_ket}\uses{bra, ket}\lean{bra_adjoint_eq_ket}\leanok
  Given $x\in \Hcal$, we get $\bra{x}^*=\ket{x}$.
\end{lemma}
\begin{proof}\leanok
  Easy computation.
\end{proof}
\begin{corollary}\label{bra-ket}\uses{bra, ket}\lean{bra_ket_one_eq_inner}\leanok
  Given $x,y\in\Hcal$, we get $\bra{x}\circ\ket{y}(1)=\ip{x}{y}$.
\end{corollary}
\begin{proof}\leanok
  Straightforward computation.
\end{proof}
\begin{corollary}\label{unit_eq_ket_one}
  \uses{ket}
  \lean{algebraMapCLM_eq_ket_one}\leanok
  Let $\Acal$ be an algebra and a Hilbert space. Then the unit map $\eta\colon\CC\to\Acal$ (which is given by $\alpha\mapsto \alpha1$) is exactly $\ket{1}$.
\end{corollary}
\begin{proof}\leanok
  True by definition.
\end{proof}
\begin{corollary}\label{unit_adjoint_eq_bra_one}\uses{bra}\lean{algebraMapCLM_adjoint_eq_bra_one}\leanok
  The adjoint of the unit map $\eta\colon\CC\to\Acal$ in an algebra and Hilbert space $\Acal$ is $\bra{1}$.
 \end{corollary}
 \begin{proof}\uses{unit_eq_ket_one, bra_adjoint_eq_ket}\leanok
  Use Lemma \ref{bra_adjoint_eq_ket} and Corollary \ref{unit_eq_ket_one}.
 \end{proof}

\section{Ket-bras}
\begin{definition}\label{rankOne}\uses{ket, bra}\lean{rankOne}\leanok
  A \textit{ket-bra} operator $\ketbra{\cdot}{\cdot}$ is defined as the linear map from $E_2$ to the anti-linear map $E_1\to\Bcal(E_1,E_2)$ and is given by
  \begin{align*}
    x\mapsto(y\mapsto(u\mapsto\ip{y}{u}x)).
  \end{align*}
  This is exactly $\ketbra{\cdot}{\cdot}=\ket{\cdot}\,\circ\,\bra{\cdot}$.
\end{definition}
Let $E_1,E_2,E_3$ be inner product spaces over $\CC$.
So given $x\in{E_2}$ and $y\in{E_1}$, we write $\ketbra{x}{y}$ to mean the map $u\mapsto\ip{y}{u}x$.

 \begin{lemma}\label{linearMap_comp_rankOne}\uses{rankOne}\lean{ContinuousLinearMap.comp_rankOne}\leanok
  Given a linear map $T_1\in\Bcal(E_2,E_3)$ and elements $x\in E_2$, $y\in{E_1}$, we get, $T_1\circ\ketbra{x}{y}=\ketbra{T_1(x)}{y}$
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}
 
 \begin{lemma}\label{rankOne_comp_linearMap}\uses{rankOne}\lean{ContinuousLinearMap.rankOne_comp}\leanok
  Given a linear map $T_2\in\Bcal(E_3,E_1)$ and elements $x\in E_2$, $y\in E_1$, we get $\ketbra{x}{y}\circ T_2=\ketbra{x}{T_2^*(y)}$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}
 
 \begin{lemma}\label{rankOne_adjoint}\uses{rankOne}\lean{rankOne_adjoint}\leanok
  Given $x\in E_2$ and $y\in E_1$, we get $\ketbra{x}{y}^*=\ketbra{y}{x}$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{lemma}\label{sum_rankOne_onb_eq_id}\uses{rankOne}\lean{rankOne.sum_orthonormalBasis_eq_id}\leanok
  Given an orthonormal basis $(u_i)$ of a $\CC$-inner product space $E$, we get $\sum_i\ketbra{u_i}{u_i}=\id$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{lemma}\label{ContinuousLinearMap.centralizer}\lean{ContinuousLinearMap.commutes_with_all_iff}\leanok
  Given a Hilbert space $\Hcal$, we have ${\Bcal(\Hcal)}^\prime=\{\alpha\id:\alpha\in\CC\}$.\\
  In other words, $x\in\Bcal(\Hcal)$ commutes with all operators $y\in\Bcal(\Hcal)$ if and only if $x=\alpha\id$ for some $\alpha\in\CC$.
 \end{lemma}
 \begin{proof}\uses{rankOne_adjoint, rankOne_comp_linearMap, linearMap_comp_rankOne}\leanok
  Let $x\in\Bcal(\Hcal)$. Obviously, if $x=\alpha\id$ for some $\alpha\in\CC$, then it commutes with every other operator. Now suppose $x$ commutes with every operator in $\Bcal(\Hcal)$.
  So this means $\ketbra{a}{x^*(b)}=\ketbra{a}{b}x=x\ketbra{a}{b}=\ketbra{x(a)}{b}$ for all $a,b\in\Hcal$.
  Suppose there exists some non-zero $a\in\Hcal$, otherwise this is trivial. Then, for any $b\in\Hcal$, we have
  \[x(b)=\frac{\norm{a}^2}{\norm{a}^2}x(b)=\frac{1}{\norm{a}^2}\ketbra{x(b)}{a}(a)=\frac{1}{\norm{a}^2}\ketbra{b}{x^*(a)}(a)=\frac{\ip{x^*(a)}{a}}{\norm{a}^2}b.\]
  Thus $x=\alpha\id$ where $\alpha=\ip{x^*(a)}{a}/\norm{a}^2$.
 \end{proof}

 \begin{proposition}\label{colinear_of_rankOne_self_eq_rankOne_self}\uses{rankOne}\lean{colinear_of_rankOne_self_eq_rankOne_self}\leanok
  Let $\Hcal$ be a Hilbert space, and let $x,y\in\Hcal$. Then if $\ketbra{x}{x}=\ketbra{y}{y}$, then there exists some $0\neq\alpha\in\CC$ such that $x=\alpha{y}$ (i.e., they are co-linear).
 \end{proposition}
 \begin{proof}\leanok
  Suppose $\ketbra{x}{x}=\ketbra{y}{y}$. Then it is clear that we get $x=0$ if and only if $y=0$. So we assume $x\neq0$ (and so $y\neq0$), otherwise this is trivial.
  Then we have \[\norm{x}^2x=\ketbra{x}{x}(x)=\ketbra{y}{y}(x)=\ip{y}{x}y.\]
  And as $x\neq0$, we get $x=\dfrac{\ip{y}{x}}{\norm{x}^2}y$. We have $\ip{y}{x}\neq0$ (otherwise, this would mean $x=0$ which is a contradiction). Thus we can let $\alpha=\ip{y}{x}/\norm{x}^2\neq0$ such that $x=\alpha{y}$.
 \end{proof}


 \begin{lemma}\label{LinearMap.isPositive_iff_eq_sum_rankOne}\uses{rankOne}\lean{LinearMap.isPositive_iff_eq_sum_rankOne}\leanok
  Given a finite-dimensional inner product space $E$ over $\CC$ and $T\in\Bcal(E)$, we get\\
  \hspace*{0.5cm}$T$ is positive semi-definite $\LRa$ $T=\sum_i\ketbra{v_i}{v_i}$ for some tuple $(v_i)$ in $E$.
 \end{lemma}
 \begin{proof}\uses{sum_rankOne_onb_eq_id}\leanok {\ }
 \begin{description}
  \item[$(\tto)$]
   Suppose $0\leq{T}$. We use the spectral theorem and let $(v_i)$ be the eigenbasis of $T$ in $E$ with corresponding eigenvalues $(\lambda_i)$. Note that, as $0\leq{T}$, we also get each $0\leq\lambda_i$. So then let each $x_i=\sqrt{\lambda_i}u_i$. Then we have $\sum_i\ketbra{x_i}{x_i}=\sum_i\sqrt{\lambda_i}\overline{\sqrt{\lambda_i}}\ketbra{u_i}{u_i}=\sum_i\lambda_i\ketbra{u_i}{u_i}=T$, where the last equality comes from Corollary \ref{sum_rankOne_onb_eq_id}.
  \item[$(\ott)$]
   Suppose we have some tuple $(v_i)$ in $E$ such that $T=\sum_i\ketbra{v_i}{v_i}$. Then, for any $x\in{E}$, we get
   $\ip{x}{T(x)}=\sum_i\ip{x}{v_i}\ip{v_i}{x}=\sum_i\abs{\ip{x}{v_i}}^2\geq0$.
   Thus $T$ is positive semi-definite.
 \end{description}
 \end{proof}

 Given an orthonormal basis $b=(b_i)$ of a finite-dimensional Hilbert space $\Hcal$, we define $R_b$ to be the linear isomorphism $\Hcal\cong\CC^{\dim\Hcal}$ given by $R_b(x)_i=\ip{b_i}{x}$ with its inverse given by $x\mapsto\sum_ix_ib_i$.
 \begin{lemma}\label{repr_adjoint}\lean{OrthonormalBasis.repr_adjoint'}\leanok
  Let $e=(e_i)$ be an orthonormal basis of a finite-dimensional Hilbert space $\Hcal$. Then $R_e^*=R_e^{-1}$.
 \end{lemma}
 \begin{proof}\leanok
  Let $x\in\Hcal$ and $y\in\CC^{\dim\Hcal}$. Then we compute,
  \begin{align*}
   \ip{x}{R_e^*(y)}_{\Hcal} &= \ip{R_e(x)}{y}_{\CC^{\dim\Hcal}} = \sum_i\ip{R_e(x)_i}{y_i}_{\CC} = \sum_i\ip{\ip{e_i}{x}_{\Hcal}}{y_i}_{\CC}\\
   &= \sum_i\ip{x}{e_i}_{\Hcal}y_i = \sum_i\ip{x}{y_ie_i}_{\Hcal}=\ip{x}{R_e^{-1}(y)}_{\Hcal}.
  \end{align*}
  Thus $R_e^*=R_e^{-1}$.
 \end{proof}
 Given orthonormal bases $b=(b_i)$ and $c=(c_j)$ of Hilbert spaces $\Hcal_1,\Hcal_2$, then we let $\mathcal{M}$ denote the identification from $\Bcal(\Hcal_1,\Hcal_2)$ to $M_{\dim\Hcal_2,\dim\Hcal_1}$, which is given by $\Mcal_{b,c}(T)_{kp}=\ip{c_k}{T(b_p)}$.
 \begin{lemma}\label{rankOne_toMatrix}\uses{rankOne}\lean{rankOne_toMatrix_of_onb}\leanok
  Given orthonormal bases $b=(b_i)$ and $c=(c_j)$ of finite-dimensional Hilbert spaces $\Hcal_1,\Hcal_2$, and elements $x\in\Hcal_1$ and $y\in\Hcal_2$, we have $\mathcal{M}_{c,b}(\ketbra{x}{y})=R_b(x){R_c(y)}^*$.
 \end{lemma}
 \begin{proof}\leanok
  For any $i\in[\dim\Hcal_1],j\in[\dim\Hcal_2]$, we compute,
  \[\mathcal{M}_{c,b}(\ketbra{x}{y})_{ij}=\ip{b_i}{\ketbra{x}{y}(c_j)}=\ip{b_i}{x}\ip{y}{c_j}=R_b(x)_i\overline{R_c(y)_j}=\left(R_b(x){R_c(y)}^*\right)_{ij}.\]
  Thus $\mathcal{M}_{c,b}(\ketbra{x}{y})=R_b(x){R_c(y)}^*$.
 \end{proof}

\chapter{Star-preserving maps}
 In this section, we define what it means for a linear map to be \textit{real} (also known as \textit{star-preserving}) on Hilbert spaces $\Hcal_1,\Hcal_2$.
 
 \begin{definition}\label{LinearMap.IsReal}\lean{LinearMap.IsReal}\leanok
  We say $A\in\Bcal(\Hcal_1,\Hcal_2)$ is \textit{real} (\textit{star-preserving}) when $A(a^*)={A(a)}^*$ for each $a\in\Hcal_1$.
 \end{definition}
 
 \begin{definition}\label{LinearMap.real}\lean{LinearMap.real}\leanok
  We define the map $\cdot^{\operatorname{r}}$ as the self-invertible anti-linear automorphism $(\Hcal_1\to\Hcal_2)\cong(\Hcal_1\to\Hcal_2)$ given by
  \[A\mapsto(a\mapsto{A(a^*)}^*).\]
 \end{definition}

 \begin{lemma}\label{LinearMap.isReal_iff}\uses{LinearMap.IsReal, LinearMap.real}\lean{LinearMap.isReal_iff}\leanok
  Let $A\in\Bcal(\Hcal_1,\Hcal_2)$. Then $A$ is real if and only if $A^{\operatorname{r}}=A$.
 \end{lemma}
 \begin{proof}\leanok
  Clearly $A^{\operatorname{r}}(x)={A(x^*)}^*=A(x)$ if and only if $A(x^*)={A(x)}^*$ for all $x\in\Hcal$, which means $A$ is real.
 \end{proof}

 \begin{lemma}\label{LinearMap.real_comp}\uses{LinearMap.real}\lean{LinearMap.real_comp}\leanok
  When $f\in\Bcal(\Hcal_1,\Hcal_2)$ and $g\in\Bcal(\Hcal_3,\Hcal_1)$, then we get ${(f\circ g)}^{\operatorname{r}}={f^{\operatorname{r}}}\circ{{g^{\operatorname{r}}}}$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{lemma}\label{TensorProduct.map_real}\uses{LinearMap.real}\lean{TensorProduct.map_real}\leanok
  Given Hilbert spaces $\Hcal_1,\Hcal_2,\Hcal_3,\Hcal_4$, and linear maps $x\colon\Hcal_1\to\Hcal_2$ and $y\colon\Hcal_3\to\Hcal_4$, we clearly get $\real{(x\otimes y)}=\real{x}\otimes\real{y}$.
 \end{lemma}
 \begin{proof}\leanok
  Straightforward computation.
 \end{proof}

 \begin{proposition}\label{LinearMap.real.spectrum}\uses{LinearMap.real}
  \lean{LinearMap.real.spectrum}\leanok
  Given $A\in\Bcal(\Hcal)$, we get $\Spectrum(\real{A})=\overline{\Spectrum(A)}$.\\
  In fact, $x\in\ker(A-\lambda\id)$ if and only if $x^*\in\ker(\real{A}-\bar{\lambda}\id)$.
 \end{proposition}
 \begin{proof}\leanok
  For any $x\in\Hcal$, we have $\real{A}(x^*)={A(x)}^*$. So if $x$ is an eigenvector of $A$ with eigenvalue $\lambda$, then clearly $\real{A}(x^*)=\bar{\lambda}x^*$, so $x^*$ is an eigenvector of $\real{A}$ with eigenvalue $\bar{\lambda}$.
  If, on the other hand, $x^*$ is an eigenvector of $\real{A}$ with eigenvalue $\bar{\lambda}$, then ${A(x)}^*=\bar{\lambda}x^*$, and so $A(x)=\lambda x$, which means $x$ is an eigenvector of $A$ with eigenvalue $\lambda$.
 \end{proof}

\chapter{The inner product}

 \section{On $M_n$}

  \begin{definition}\label{Dual.matrix}\lean{Module.Dual.matrix}\leanok
   Given a linear functional $\phi\colon M_n \to \CC$, we define $\phi_Q=\sum_{i,j}\phi(e_{ij})e_{ji}$.
  \end{definition}

  \begin{lemma}\label{dual_eq_trace}\uses{Dual.matrix}\lean{Module.Dual.apply}\leanok
   Given a linear functional $\phi\colon M_n\to\CC$, we get $\phi$ is given by $x\mapsto\Tr(\phi_Q \,x)$.
  \end{lemma}
  \begin{proof}\leanok
   Straightforward computation.
  \end{proof}

  \begin{definition}\label{LinearMap.IsPosMap}\lean{LinearMap.IsPosMap}\leanok
   Given C$^*$-algebras $A,C$, we say a linear map $f\colon A \to C$ is \textit{positive} when $0\leq f(a)$ for all $0\leq a$. In other words, $f$ maps positive elements in $A$ to positive elements in $C$.
  \end{definition}

  As any matrix $x\in{M_n}$ is positive if and only if there exists some $y\in M_n$ such that $x=y^*y$, we get that a linear functional $f$ on $M_n$ is a \textit{positive map} when $0\leq{f(x^*x)}$ for any matrix $x\in{M_n}$.

  \begin{lemma}\label{Dual.isPosMap_iff_of_matrix}\uses{Dual.matrix, LinearMap.IsPosMap}\lean{Module.Dual.isPosMap_iff_of_matrix}\leanok
   Given a linear functional $\phi$ on $M_n$, we have,\\
   \hspace*{0.5cm}$\phi$ is positive $\,\LRa\,$ $0\leq\phi_Q$.\\
   Here, $\phi_Q$ is the matrix of $\phi$ defined in Definition \ref{Dual.matrix}.
  \end{lemma}
  \begin{proof}\uses{dual_eq_trace, LinearMap.isPositive_iff_eq_sum_rankOne}\leanok
   By Lemma \ref{dual_eq_trace} we have $\phi(x)=\Tr(\phi_Q\, x)$ for all $x\in{M_n}$.
   \begin{description}
    \item[$(\tto)$]
     Suppose $\phi$ is positive. By Lemma \ref{LinearMap.isPositive_iff_eq_sum_rankOne}, we get $0\leq\sum_i\phi(x_ix_i^*)$ for any tuple $(x_i)$ in $\CC^n$. So then for any $x\in\CC^n$, we have $0\leq\phi(xx^*)=\Tr(\phi_Q\, xx^*)=x^*\phi_Q\, x$, which means $\phi_Q$ is positive semi-definite.
    \item[$(\ott)$]
     Suppose $\phi_Q$ is positive semi-definite. Then since $\phi_Q$ is positive semi-definite, we have $\phi_Q=\phi_Q^{1/2}\phi_Q^{1/2}$, where $\phi_Q^{1/2}$ is also positive semi-definite (and so is self-adjoint). So for any $x\in{M_n}$, we have $\phi(x^*x)=\Tr(\phi_Q\, x^*x)=\Tr\left({(x\phi_Q^{1/2})}^*(x\phi_Q^{1/2})\right)\geq0$.
   \end{description}
   Thus $\phi$ is a positive map if and only if our matrix $\phi_Q$ is positive semi-definite.
  \end{proof}

  \begin{proposition}\label{Dual.isReal_iff}\uses{LinearMap.IsReal, Dual.matrix}\lean{Module.Dual.isReal_iff}\leanok
   Given a linear functional $\phi\colon{M_n}\to\CC$, we get $\phi$ is real (star-preserving) if and only if $\phi_Q$ is self-adjoint.\\
   Here, $\phi_Q$ is the matrix given by $\phi$ defined in Definition \ref{Dual.matrix}.
  \end{proposition}
  \begin{proof}\uses{dual_eq_trace}\leanok {\ }
   \begin{description}
    \item[$(\tto)$]
     Suppose $\phi$ is star-preserving, i.e., $\phi(x^*)=\overline{\phi(x)}$ for all $x\in{M_n}$.
     We let $x\in{M_n}$, and compute using Lemma \ref{dual_eq_trace},
     \[\Tr(\phi_Q\, x^*)=\phi(x^*)=\overline{\phi(x)}=\overline{\Tr(\phi_Q\, x)}=\Tr(x^*\phi_Q^*),\]
     And so $\phi_Q=\phi_Q^*$.
    \item[$(\ott)$]
     Suppose $\phi_Q$ is self-adjoint. Using Lemma \ref{dual_eq_trace}, $\phi$ is given by $x\mapsto\Tr(\phi_Q\, x)$.
     And so for any $x\in{M_n}$, we get $\phi(x^*)=\Tr(\phi_Q\, x^*)=\Tr({(x\phi_Q)}^*)=\overline{\Tr(x\phi_Q)}=\overline{\phi(x)}$.
     Thus, $\phi$ is real.
   \end{description}
  \end{proof}

\begin{corollary}\label{Matrix.isPosSemidef_and_invertible_iff_isPosDef}\lean{Matrix.PosSemidef.invertible_iff_posDef}\leanok
  If $A\in{M_n}$. Then\\
  \hspace*{0.5cm}$0\leq{A}$ and is invertible $\,\LRa\,$ $A$ is positive-definite.
 \end{corollary}
 \begin{proof}\leanok {\ }
  \begin{description}
   \item[$(\tto)$]
    Suppose $0\leq{A}$ and $A=A^{1/2}A^{1/2}$ is invertible. Then $A^{1/2}$ is also invertible and positive semi-definite. Let $v\in\CC^n$ be non-zero.
    Then, we compute,
    \[\ip{v}{Av}=\ip{v}{A^{1/2}A^{1/2}v}=\ip{A^{1/2}v}{A^{1/2}v}>0,\]
    since $A^{1/2}v\neq0$ (as $A^{1/2}$ is invertible). Note that, in the second equality, we use the self-adjointed-ness of $A^{1/2}$ since it is positive semi-definite. So we are done.
   \item[$(\ott)$]
    Suppose $0<A$. Then obviously $0\leq{A}$, so we only need to check if it is invertible. Suppose the contrary, i.e., $A$ is not invertible. Then there exists a non-zero $v\in\CC^n$ such that $Av=0$. But then, by the hypothesis, we get $0<\ip{v}{Av}=0$, which is a contradiction. Thus $A$ is invertible.
  \end{description}
 \end{proof}


\begin{lemma}\label{PosDef.trace_conjTranspose_mul_self_eq_zero_iff}\lean{Matrix.PosDef.trace_conjTranspose_hMul_self_eq_zero}\leanok
  Given a positive definite matrix $Q\in{M_n}$, we have $\Tr(Qx^*x)=0$ if and only if $x=0$ for any $x\in{M_n}$.
 \end{lemma}
 \begin{proof}\uses{Matrix.isPosSemidef_and_invertible_iff_isPosDef}\leanok
  We have $\Tr\left({(xQ^{1/2})}^*(xQ^{1/2})\right)=\Tr(Qx^*x)=0$ if and only if $xQ^{1/2}=0$. As $Q^{1/2}$ is positive definite, we get it is also invertible by Corollary \ref{Matrix.isPosSemidef_and_invertible_iff_isPosDef}, and so $xQ^{1/2}=0$ if and only if $x=0$. And so we are done.
 \end{proof}

  \begin{definition}\label{Dual.IsFaithful}\lean{Module.Dual.IsFaithful}\leanok
   A linear functional $f$ on $A$ is said to be \textit{faithful} if $f(x^*x)=0$ if and only if $x=0$ for all $x\in A$.
  \end{definition}

  \begin{proposition}\label{Dual.isFaithfulPosMap_iff}
    \uses{LinearMap.IsPosMap, Dual.IsFaithful, Dual.matrix}
    \lean{Module.Dual.isFaithfulPosMap_iff_of_matrix}\leanok
    Given a linear functional $\phi\colon{M_n}\to\CC$, we have\\
    \hspace*{0.5cm}$\phi$ is a positive and faithful map $\,\LRa\,$ $\phi_Q$ is positive-definite.\\
    Again, $\phi_Q$ is the matrix given by $\phi$ defined in Definition \ref{Dual.matrix}.
   \end{proposition}
   \begin{proof}\uses{dual_eq_trace, Dual.isPosMap_iff_of_matrix, PosDef.trace_conjTranspose_mul_self_eq_zero_iff}\leanok
    By Lemma \ref{dual_eq_trace}, we have $\phi$ is given by $x\mapsto\Tr(\phi_Q\, x)$, and by Lemma \ref{Dual.isPosMap_iff_of_matrix}, we know $\phi$ is positive if and only if $0\leq\phi_Q$.
    So we need to show that faithfulness of a positive linear functional is equivalent to $\phi_Q$ being positive definite.
    \begin{description}
     \item[$(\tto)$]
      Suppose $\phi$ is faithful and positive.
      So we have $\phi(x)=0$ if and only if $x=0$ for any positive semi-definite matrix $x\in{M_n}$.
      Let $0\neq{x}\in\CC^n$. Then we have $xx^*\neq0$ as $x\neq0$. This means, by faithfulness and positivity of $\phi$ we get $\phi(xx^*)\neq0$ as $xx^*$ is a non-zero positive semi-definite matrix. And so $0<\phi(xx^*)=\Tr(\phi_Q\, xx^*)=x^*\phi_Q\, x$, which means $\phi_Q$ is positive definite.
     \item[$(\ott)$]
      Suppose $\phi_Q$ is positive definite. Then for any $x\in{M_n}$, we get $\phi(x^*x)=\Tr(\phi_Q\, xx^*)=0$ if and only if $x=0$ using Lemma \ref{PosDef.trace_conjTranspose_mul_self_eq_zero_iff}.
    \end{description}
    Thus $\phi$ is a faithful and positive linear functional if and only if the matrix $\phi_Q$ is positive definite.
   \end{proof}

  \begin{theorem}\label{Dual.isFaithfulPosMap_tfae}
   \uses{LinearMap.IsPosMap, Dual.IsFaithful}
   \lean{Module.Dual.isFaithfulPosMap_of_matrix_tfae}
   Given a linear functional $\phi\colon{M_n}\to\CC$, then the following are equivalent,
   \begin{enumerate}[label=(\roman*)]
    \item $\phi$ is positive and faithful,
    \item $\exists!Q\in{M_n}:Q\text{ is pos-def and }\forall{x}\in{M_n}:\phi(x)=\Tr(Qx)$,
    \item $M_n\times{M_n}\to\CC\colon(x,y)\mapsto\phi(x^*y)$ defines an inner product on $M_n$.
   \end{enumerate}
  \end{theorem}
  \begin{proof}\uses{dual_eq_trace, Dual.isReal_iff, Dual.isFaithfulPosMap_iff}
  \end{proof}

 \section{On $\bigoplus_i M_{n_i}$}
  
 


 